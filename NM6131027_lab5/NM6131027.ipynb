{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KRm0_WztAPe"
      },
      "source": [
        "# 2025 EAI Lab 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e7m9tHTpR0H"
      },
      "source": [
        "## Topic 1 : From PyTorch To ONNX\n",
        "\n",
        "### Steps:\n",
        "1.   Define Model Architecture\n",
        "2.   Load Weight\n",
        "3.   Export ONNX File\n",
        "4.   Quantize To INT8\n",
        "5.   Building Session\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vt7LM45spK0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1db527-1bfa-4ad2-811f-7cbc1665bdba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting onnxruntime-tools\n",
            "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-6.0.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from onnxruntime-tools) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from onnxruntime-tools) (9.0.0)\n",
            "Collecting py3nvml (from onnxruntime-tools)\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Collecting gradio-client==2.0.1 (from gradio)\n",
            "  Downloading gradio_client-2.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting xmltodict (from py3nvml->onnxruntime-tools)\n",
            "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.5.6-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.0/683.0 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-6.0.2-py3-none-any.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-2.0.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.12-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: xmltodict, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, py3nvml, onnx, nvidia-cusparse-cu12, nvidia-cufft-cu12, coloredlogs, onnxruntime-tools, onnxruntime-gpu, onnxruntime, onnx_ir, nvidia-cusolver-cu12, gradio-client, torch, onnxscript, gradio, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.9.0+cu126\n",
            "    Uninstalling torchaudio-2.9.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Successfully installed coloredlogs-15.0.1 gradio-6.0.2 gradio-client-2.0.1 humanfriendly-10.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 onnx-1.20.0 onnx_ir-0.1.12 onnxruntime-1.23.2 onnxruntime-gpu-1.23.2 onnxruntime-tools-1.7.0 onnxscript-0.5.6 py3nvml-0.2.7 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1 triton-3.5.1 xmltodict-1.0.2\n"
          ]
        }
      ],
      "source": [
        " !pip install -U \\\n",
        "     torch torchvision torchaudio \\\n",
        "     onnx onnxscript onnxruntime onnxruntime-tools onnxruntime-gpu \\\n",
        "     gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MCKZlTEIqkOD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# TODO\n",
        "# Design Your ResNet18 Model\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "                    nn.BatchNorm2d(out_channels),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                    nn.BatchNorm2d(out_channels)\n",
        "                )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, s))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RUErZRINpUU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da27af4-8d40-47f7-eefd-a6067f5701d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from best_model.pth...\n",
            "Weights loaded successfully.\n",
            "[torch.onnx] Obtain model graph for `ResNet18([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ResNet18([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 40 of general pattern rewrite rules.\n"
          ]
        }
      ],
      "source": [
        "torch_model = ResNet18(num_classes=10)\n",
        "dummy_input = (torch.randn(1, 3, 32, 32),)\n",
        "\n",
        "def export_onnx(model, dummy, path):\n",
        "  print(f\"Loading weights from {path}...\")\n",
        "  try:\n",
        "      state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "      if 'state_dict' in state:\n",
        "          state = state['state_dict']\n",
        "\n",
        "      new_state_dict = {}\n",
        "      for k, v in state.items():\n",
        "          name = k.replace(\"module.\", \"\")\n",
        "\n",
        "          if \"total_ops\" in name or \"total_params\" in name:\n",
        "              continue\n",
        "\n",
        "          new_state_dict[name] = v\n",
        "\n",
        "      model.load_state_dict(new_state_dict)\n",
        "      print(\"Weights loaded successfully.\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"Error loading weights: {e}\")\n",
        "      return\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  # Todo : Export ONNX FILE\n",
        "  torch.onnx.export(\n",
        "      model,\n",
        "      dummy,\n",
        "      \"NM6131027_FP32.onnx\",\n",
        "      input_names=[\"input\"],\n",
        "      output_names=[\"output\"],\n",
        "      opset_version=18,\n",
        "  )\n",
        "  pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # 提醒 : 記得先把 best_model.pth 上傳到 Content 資料夾\n",
        "  export_onnx(model=torch_model, dummy=dummy_input, path=\"best_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PnBfgSxfpUzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac94bbf-0249-4b8c-83bf-4848459f2aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calib will use input name: input\n"
          ]
        }
      ],
      "source": [
        "import os, numpy as np\n",
        "from PIL import Image\n",
        "import onnxruntime as ort\n",
        "from onnxruntime.quantization import CalibrationDataReader\n",
        "\n",
        "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
        "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
        "\n",
        "def preprocess_32x32(pil_img: Image.Image) -> np.ndarray:\n",
        "    arr = np.asarray(pil_img.convert(\"RGB\").resize((32, 32)), dtype=np.float32) / 255.0\n",
        "    arr = (arr - CIFAR10_MEAN) / CIFAR10_STD\n",
        "    return arr.transpose(2, 0, 1)[None, ...]  # (1,3,32,32)\n",
        "\n",
        "class CIFARLikeCalibReader(CalibrationDataReader):\n",
        "    def __init__(self, image_dir: str = None, input_name: str = \"input\",\n",
        "                 batch_size: int = 32, num_batches: int = 10):\n",
        "        self.input_name  = input_name\n",
        "        self.batch_size  = batch_size\n",
        "        self.num_batches = num_batches\n",
        "        self.paths = []\n",
        "        if image_dir and os.path.isdir(image_dir):\n",
        "            for f in os.listdir(image_dir):\n",
        "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
        "                    self.paths.append(os.path.join(image_dir, f))\n",
        "        self._mode_random = len(self.paths) == 0\n",
        "        self._pos = 0\n",
        "        self._emitted = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self._emitted >= self.num_batches:\n",
        "            return None\n",
        "        if self._mode_random:\n",
        "            batch = np.random.randn(self.batch_size, 3, 32, 32).astype(np.float32)\n",
        "        else:\n",
        "            items = []\n",
        "            for _ in range(self.batch_size):\n",
        "                if self._pos >= len(self.paths):\n",
        "                    break\n",
        "                img = Image.open(self.paths[self._pos])\n",
        "                self._pos += 1\n",
        "                items.append(preprocess_32x32(img))\n",
        "            if not items:\n",
        "                return None\n",
        "            batch = np.concatenate(items, axis=0).astype(np.float32)\n",
        "        self._emitted += 1\n",
        "        return {self.input_name: batch}\n",
        "\n",
        "    def rewind(self):\n",
        "        self._pos = 0\n",
        "        self._emitted = 0\n",
        "\n",
        "FP32_MODEL = \"NM6131027_FP32.onnx\"\n",
        "INT8_MODEL = \"NM6131027_INT8.onnx\"\n",
        "\n",
        "\n",
        "_tmp = ort.InferenceSession(FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n",
        "INPUT_NAME = _tmp.get_inputs()[0].name\n",
        "print(\"Calib will use input name:\", INPUT_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9_HL4D23phIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54f440c-27a7-4780-93d4-2dd402b5a67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
            "WARNING:root:Please use QuantFormat.QDQ for activation type QInt8 and weight type QInt8. Or it will lead to bad performance on x64.\n",
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved INT8 model: NM6131027_INT8.onnx\n"
          ]
        }
      ],
      "source": [
        "from onnxruntime.quantization import quantize_static, QuantType, CalibrationMethod\n",
        "\n",
        "\n",
        "\n",
        "reader = CIFARLikeCalibReader(\n",
        "    image_dir=None,\n",
        "    input_name=INPUT_NAME,\n",
        "    batch_size=1,\n",
        "    num_batches=50\n",
        ")\n",
        "\n",
        "\n",
        "def quantize_to_int8(fp32_path, int8_path, reader, method=\"MinMax\"):\n",
        "    # Todo : quantize_static\n",
        "    quantize_static(\n",
        "            model_input=fp32_path,\n",
        "            model_output=int8_path,\n",
        "            calibration_data_reader=reader,\n",
        "            quant_format=\"QOperator\",\n",
        "            per_channel=True,\n",
        "            weight_type=QuantType.QInt8,\n",
        "        )\n",
        "    print(\"Saved INT8 model:\", INT8_MODEL)\n",
        "\n",
        "quantize_to_int8(FP32_MODEL, INT8_MODEL, reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VYZIE2Rdpj3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab28be2-deca-42dc-eb82-083075f9a868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Check] relative L2 diff FP32 vs INT8: 0.009624\n",
            "FP32 avg sec: 0.015335793495178223\n",
            "INT8 avg sec: 0.013750042915344238\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "def run(sess, x):\n",
        "    return sess.run(None, {sess.get_inputs()[0].name: x})[0]\n",
        "\n",
        "x_demo = np.random.randn(1,3,32,32).astype(np.float32)\n",
        "\n",
        "# Todo : build session function\n",
        "def build_session(model_path, providers):\n",
        "  session = ort.InferenceSession(model_path, providers=providers)\n",
        "  return session\n",
        "\n",
        "\n",
        "sess_fp32 = build_session(model_path=FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n",
        "sess_int8 = build_session(model_path=INT8_MODEL, providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "y_fp32 = run(sess_fp32, x_demo)\n",
        "y_int8 = run(sess_int8, x_demo)\n",
        "\n",
        "l2_rel = np.linalg.norm(y_fp32 - y_int8) / (np.linalg.norm(y_fp32) + 1e-12)\n",
        "print(f\"[Check] relative L2 diff FP32 vs INT8: {l2_rel:.6f}\")\n",
        "\n",
        "def bench(sess, x, n=50):\n",
        "    t0 = time.time()\n",
        "    for _ in range(n):\n",
        "        sess.run(None, {sess.get_inputs()[0].name: x})\n",
        "    return (time.time() - t0) / n\n",
        "\n",
        "print(\"FP32 avg sec:\", bench(sess_fp32, x_demo))\n",
        "print(\"INT8 avg sec:\", bench(sess_int8, x_demo))\n",
        "\n",
        "so = ort.SessionOptions()\n",
        "so.enable_profiling = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeFccLG1pehx"
      },
      "source": [
        "## Topic 2 : Gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qFNo0K7gvJqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa1a513-4160-4be0-fca8-98235c0ec2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<13.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_vE9Tel_tI76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "d3d1567d-ddff-468f-b28b-d8c5e5b2640f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3d8a45baef4025a906.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3d8a45baef4025a906.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "# ====== Config ======\n",
        "MODEL_PATH_INT8 = \"NM6131027_INT8.onnx\"\n",
        "MODEL_PATH_FP32 = \"NM6131027_FP32.onnx\"\n",
        "LABELS = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "# CIFAR-10 Normalization Parameter\n",
        "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
        "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
        "\n",
        "# ====== Utils ======\n",
        "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
        "    x = x - np.max(x)\n",
        "    ex = np.exp(x)\n",
        "    return ex / np.sum(ex)\n",
        "\n",
        "# TODO : preprocess input image function\n",
        "def preprocess(image: Image.Image) -> np.ndarray:\n",
        "    \"\"\"輸入 PIL Image → (1,3,32,32) float32\"\"\"\n",
        "    if not isinstance(image, Image.Image):\n",
        "        raise ValueError(\"Plese Upload Image\")\n",
        "\n",
        "    img = image.resize((32, 32))\n",
        "\n",
        "    arr = np.array(img).astype(np.float32) / 255.0\n",
        "\n",
        "    arr = (arr - CIFAR10_MEAN) / CIFAR10_STD\n",
        "\n",
        "    arr = arr.transpose(2, 0, 1)\n",
        "\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    return arr\n",
        "\n",
        "# ====== ONNX Sessions ======\n",
        "providers = ort.get_available_providers()\n",
        "\n",
        "sess_int8 = build_session(MODEL_PATH_INT8, providers=providers)\n",
        "in_int8  = sess_int8.get_inputs()[0].name\n",
        "out_int8 = sess_int8.get_outputs()[0].name\n",
        "\n",
        "\n",
        "try:\n",
        "    sess_fp32 = build_session(MODEL_PATH_FP32, providers=providers)\n",
        "    in_fp32  = sess_fp32.get_inputs()[0].name\n",
        "    out_fp32 = sess_fp32.get_outputs()[0].name\n",
        "    _fp32_err = \"\"\n",
        "except Exception as e:\n",
        "    sess_fp32, in_fp32, out_fp32 = None, None, None\n",
        "    _fp32_err = f\"[FP32 load failure] {type(e).__name__}: {e}\"\n",
        "\n",
        "# ====== Compare FP32 and INT8 ======\n",
        "# TODO : Compare FP32 and INT8\n",
        "def compare_fp32_int8(image: Image.Image):\n",
        "    if image is None:\n",
        "        return {}, {}, \"Please Upload Your Image。\"\n",
        "    if sess_fp32 is None:\n",
        "        return {}, {}, (_fp32_err or \"The FP32 model has not been provided, so a comparison cannot be made.\")\n",
        "\n",
        "    x = preprocess(image)\n",
        "\n",
        "    t0 = time.time()\n",
        "    res_fp32 = sess_fp32.run([out_fp32], {in_fp32: x})[0]\n",
        "    fp32_ms = (time.time() - t0) * 1000\n",
        "\n",
        "    t0 = time.time()\n",
        "    res_int8 = sess_int8.run([out_int8], {in_int8: x})[0]\n",
        "    int8_ms = (time.time() - t0) * 1000\n",
        "\n",
        "    p_fp32 = softmax_np(res_fp32[0])\n",
        "    p_int8 = softmax_np(res_int8[0])\n",
        "\n",
        "    def top3_map(p):\n",
        "        idx = np.argpartition(p, -3)[-3:]\n",
        "        idx = idx[np.argsort(p[idx])[::-1]]\n",
        "        return {LABELS[i]: float(p[i]) for i in idx}\n",
        "\n",
        "    top3_fp32 = top3_map(p_fp32)\n",
        "    top3_int8 = top3_map(p_int8)\n",
        "\n",
        "    summary = (\n",
        "        f\"FP32 inference time: {fp32_ms:.2f} ms\\n\"\n",
        "        f\"INT8 inference time: {int8_ms:.2f} ms\\n\"\n",
        "        f\"Speedup (FP32/INT8): {(fp32_ms / max(int8_ms, 1e-9)):.2f}×\"\n",
        "    )\n",
        "    return top3_fp32, top3_int8, summary\n",
        "\n",
        "# ====== Gradio UI ======\n",
        "# TODO : Building GUI Interface\n",
        "demo = gr.Interface(\n",
        "    fn = compare_fp32_int8,\n",
        "    inputs = gr.Image(type=\"pil\", label=\"Upload Image (CIFAR-10)\"),\n",
        "    outputs = [\n",
        "        gr.Label(num_top_classes=3, label=\"FP32 Prediction\"),\n",
        "        gr.Label(num_top_classes=3, label=\"INT8 Prediction\"),\n",
        "        gr.Textbox(label=\"Performance Comparison\")\n",
        "    ],\n",
        "    title = \"ResNet18 Quantization Demo: FP32 vs INT8\",\n",
        "    description = \"上傳一張圖片，比較全精度模型 (FP32) 與 量化模型 (INT8) 的預測結果與推論速度。\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TODO : building a public web\n",
        "    # share=True 會產生公開的 Gradio 網址\n",
        "    demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}